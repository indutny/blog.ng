<!DOCTYPE html>
<html>
  <head>
    <meta name=viewport content"width=device-width,initial-scale=1,maximum-scale=10" />
    
    <title>Benchmarking TLS, TLSnappy and NGINX</title>
    
    <link rel=alternate type="application/rss+xml" href="http://darksi.de/rss.xml" title="Fedor Indutny's blog">
    <link rel=stylesheet href="/css/main.css" />
  </head>
  <body>
    <aside id=info>
      <section class=info-title>
        <a href="/">darksi.de</a>
        <br/>
        of
        </br>
        Software Engineering
      </section>
    
      <section class=info-copyright>
        Copyright <a href="https://github.com/indutny">Fedor Indutny</a>,
        view <a href="http://opensource.org/licenses/mit-license.php">license</a>
      </section>
    
      <section class=info-credits>
        <i>Icons by: Bluetip Design from the Noun Project</i>
      </section>
    </aside>
    <section id=content>
      <article class=post>
        <section class=post-header>
          <button class=votewdgt title=upvote>?</button>
          <h1>Benchmarking TLS, TLSnappy and NGINX</h1>
          <span class=post-header-date>Mon Oct 01 2012 20:00:00 GMT-0400 (Eastern Daylight Time)</span>
        </section>

        <section class=post-body>
          <h1 id="tl-dr">TL;DR</h1>
<p>I&#39;ve created <a href="https://github.com/indutny/tlsnappy">TLSnappy</a> module which is going to be faster than internal TLS
module in node.js. So far it&#39;s slower on some benchmarks, but it&#39;ll definitely
be much snappier soon.</p>
<h1 id="preface">Preface</h1>
<p>Many people were complaining about <a href="http://nodejs.org/api/tls.html">tls</a> performance in node.js, which (as
they said) was significantly worse than in many other popular web servers,
balancers and terminators (i.e. nginx, haproxy..).</p>
<p>Several things were done to address this issue, including:</p>
<ul>
<li>Disabling OpenSSL compression in node:
<a href="http://journal.paul.querna.org/articles/2011/04/05/openssl-memory-use/">http://journal.paul.querna.org/articles/2011/04/05/openssl-memory-use/</a> and
<a href="https://github.com/joyent/node/commit/e83c695">https://github.com/joyent/node/commit/e83c695</a></li>
<li><a href="https://github.com/joyent/node/commit/e80cac62">Bundling a newer version of OpenSSL</a></li>
<li><a href="https://github.com/joyent/node/compare/7651228...e0e9f0c">Enabling inlined assembly</a></li>
<li><a href="https://github.com/joyent/node/commit/7651228">Using slab allocator to reduce memory allocation overhead</a></li>
</ul>
<p>After all that stuff got in, rps (requests per second) rate was significantly
improved, but many users were still unhappy with overall TLS performance.</p>
<h1 id="tlsnappy">TLSnappy</h1>
<p>This time, instead of patching and tweaking <a href="http://nodejs.org/api/tls.html">tls</a> I decided that it may be
worth trying to rewrite it from scratch as a third-party node.js addon. This
recently became <a href="https://github.com/TooTallNate/node-gyp/wiki/Linking-to-OpenSSL">possible</a>, thanks to <a href="https://github.com/TooTallNate">Nathan Rajlich</a> and his awesome
node.js native addon build tool <a href="https://github.com/TooTallNate/node-gyp">node-gyp</a>.</p>
<p>I didn&#39;t want to offer a module that&#39;s functionally equivalent to TLS, but
wanted to fix some issues (as I&#39;ve perceived them) and improve few things:</p>
<ul>
<li>Encryption/decryption should happen asynchronously (i.e. in other thread).
This could potentially speed up initial ssl handshake, and let the event loop
perform more operations while encryption/decryption is happening in the
background.</li>
<li>The builtin TLS module passes, slices and copies buffers in <a href="https://github.com/indutny/tlsnappy">javascript</a>.
All binary data operations should happen in C++.</li>
</ul>
<p>All this was implemented in <a href="https://github.com/indutny/tlsnappy">TLSnappy</a> module.</p>
<p>There were a lot of availability and stability issues (and surely much more that
I&#39;m yet unaware of). But tlsnappy seem to be quite a bit more performant than
the built-in tls module. Especially... when taking in account that <code>tlsnappy</code> is
by default using all available cores to encrypt/decrypt requests, while <code>tls</code>
module needs to be run in <a href="http://nodejs.org/api/cluster.html">cluster</a> to balance load between all cores.</p>
<h1 id="benchmarking">Benchmarking</h1>
<p>And I&#39;ve confirmed that when I was benchmaring it with Apache Benchmark (ab) on
my Macbook Pro and on dedicated Xeon server. Here a results from the latter one:</p>
<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps.png" alt="Xeon 16 threads (rps) - Apache Benchmark">
<img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-ms.png" alt="Xeon 16 threads (ms) - Apache Benchmark"></p>
<p>A little comment about curve names here:</p>
<ul>
<li><code>default</code> - one tlsnappy process with 16 threads</li>
<li><code>hybrid</code> - 4 tlsnappy processes with 4 threads each</li>
<li><code>cluster</code> - 16 tlsnappy processes with 1 thread each</li>
<li><code>http</code> - 16 node.js processes in cluster</li>
</ul>
<p>As you can see tlsnappy is faster than tls server in almost every case, except
<code>cluster</code> mode (which just wasn&#39;t saturating CPU enough). Everything looked
great and shiny, until <a href="https://github.com/mranney">Matt Ranney</a> has pointed out that <code>ab</code> results of
https benchmarks are not really trustful:</p>
<p><blockquote class="twitter-tweet tw-align-center"><p>@<a href="https://twitter.com/ryah">ryah</a> @<a href="https://twitter.com/indutny">indutny</a> I was also mislead by &quot;ab&quot; with https benchmarks. I&#39;m not sure what tool to use instead though.</p>&mdash; Matt Ranney (@mranney) <a href="https://twitter.com/mranney/status/252137849468633088" data-datetime="2012-09-29T20:08:42+00:00">September 29, 2012</a></blockquote></p>
<script src="//platform.twitter.com/widgets.js" charset="utf-8" async></script>

<p>I&#39;ve installed siege, created node.js <a href="https://github.com/indutny/tlsnappy/blob/master/benchmark/script.js">script</a> and let it run for some time:</p>
<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-rps-siege.png" alt="Xeon 16 threads (rps) - Siege"></p>
<p>Results are much better now (nginx was doing 5000 rps with siege and 2500 rps
with ab), but now tlsnappy seems to be slower than node.js&#39; default tls server.</p>
<p>I started investigation and decided to track not only rps rate, but a CPU load
too:</p>
<p><img src="https://raw.github.com/indutny/tlsnappy/master/benchmark/tlsnappy-load-siege.png" alt="Xeon 16 threads (load) - Siege"></p>
<h1 id="afterword">Afterword</h1>
<p>Right now, as you can see on the chart above, tlsnappy isn&#39;t saturating all CPUs
well. I suspect this is a major reason of its relative slowness in comparison
to both nginx and https module. I&#39;m working on making it balance and handle
requests better, and will sum up results of this investigation in the next blog
post.</p>
<p>For those of you, who are interested in more details -
<a href="https://docs.google.com/spreadsheet/ccc?key=0AhEDnA4M4EKGdDIwb3VYZTd1alA5T1pTVnlQWl9wanc">here is benchmarks&#39; data</a></p>

        </section>
      </article>
    </section>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-68572164-1', 'auto');
      ga('send', 'pageview');
    
    </script>
    <script src="https://vote.wdgt.io/cdn/snippet-v2.js" async></script>
  </body>
</html>
